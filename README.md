# Projeto de Machine Learning - An√°lise de Algoritmos e T√©cnicas

Este reposit√≥rio cont√©m implementa√ß√µes e an√°lises de diferentes algoritmos de machine learning aplicados a diversos datasets. Cada branch TPxx representa um trabalho pr√°tico espec√≠fico com t√©cnicas e abordagens distintas.

## üìä Resumo dos Trabalhos Pr√°ticos

### TP01 - Classifica√ß√£o KNN com Heart Disease Dataset

**Arquivo**: `projeto_knn_heart_unico.ipynb`

**T√©cnicas Implementadas**:
- **Algoritmo**: K-Nearest Neighbors (KNN)
- **Pr√©-processamento**: 
  - OneHotEncoder para vari√°veis categ√≥ricas
  - StandardScaler para vari√°veis num√©ricas
- **Valida√ß√£o**: Divis√£o treino/teste (80%/20%) com estratifica√ß√£o

**Features Implementadas**:
- Carregamento e identifica√ß√£o autom√°tica de features/target
- Pipeline de transforma√ß√£o de dados com ColumnTransformer
- An√°lise do impacto do par√¢metro K (1 a 20)
- Matriz de confus√£o para visualiza√ß√£o de resultados
- Gr√°fico de acur√°cia vs valor de K

**Resultados Obtidos**:
- Melhor acur√°cia obtida com an√°lise de diferentes valores de K
- Visualiza√ß√£o clara do trade-off entre complexidade e performance
- Matriz de confus√£o demonstrando classifica√ß√£o bin√°ria (doen√ßa card√≠aca)

**Informa√ß√µes T√©cnicas**:
- Dataset: Heart Disease (classifica√ß√£o bin√°ria)
- M√©trica principal: Acur√°cia
- Estrat√©gia de valida√ß√£o: Hold-out simples
- Foco: An√°lise de hiperpar√¢metros e impacto do K no KNN

---

### TP02 - Detec√ß√£o de Fake News com TF-IDF e KNN

**Arquivo**: `tp2.ipynb`

**T√©cnicas Implementadas**:
- **Algoritmo**: K-Nearest Neighbors aplicado a texto
- **Vetoriza√ß√£o**: TF-IDF (Term Frequency-Inverse Document Frequency)
- **Pr√©-processamento**: 
  - Combina√ß√£o de t√≠tulo + texto
  - Remo√ß√£o de stop words
  - N-gramas (unigramas e bigramas)

**Features Implementadas**:
- Vetoriza√ß√£o TF-IDF com 5000 features m√°ximas
- An√°lise comparativa de diferentes valores de K (3, 5, 7, 9, 11, 15, 21, 31, 51)
- Valida√ß√£o cruzada estratificada (5 folds)
- M√∫ltiplas m√©tricas de avalia√ß√£o

**Resultados Obtidos**:
- **M√©tricas de Performance**:
  - Acur√°cia, Precis√£o, Recall, F1-Score
  - Especificidade e Sensibilidade
  - AUC-ROC com curva ROC
  - Curva Precision-Recall

**Visualiza√ß√µes**:
- Matriz de confus√£o detalhada
- Curva ROC com AUC
- Gr√°fico de impacto do K nas acur√°cias
- Distribui√ß√£o de probabilidades preditas

**Informa√ß√µes T√©cnicas**:
- Dataset: Fake News (Fake.csv + True.csv)
- Classifica√ß√£o bin√°ria: Fake (0) vs True (1)
- Vetoriza√ß√£o: TF-IDF com par√¢metros otimizados
- Valida√ß√£o: Cross-validation + hold-out test
- Interpreta√ß√£o autom√°tica dos resultados baseada em m√©tricas

---

### TP03 - Classifica√ß√£o Sonar com PCA e Decision Tree

**Arquivo**: `sonar_pca_tree.ipynb`

**T√©cnicas Implementadas**:
- **Algoritmo**: Decision Tree Classifier
- **Redu√ß√£o de Dimensionalidade**: PCA (Principal Component Analysis)
- **Pipeline**: StandardScaler ‚Üí PCA ‚Üí DecisionTree
- **Otimiza√ß√£o**: GridSearchCV com valida√ß√£o cruzada

**Features Implementadas**:
- Pipeline automatizado com StandardScaler, PCA e Decision Tree
- Busca de hiperpar√¢metros para:
  - N√∫mero de componentes PCA (5, 10, 15, 20, 30, None)
  - Crit√©rio de divis√£o (gini, entropy)
  - Par√¢metros de profundidade e folhas
  - Pruning via ccp_alpha

**Resultados Obtidos**:
- **M√©tricas Completas**:
  - Acur√°cia, Precis√£o, Recall, Especificidade
  - F1-Score e ROC AUC
  - Matriz de confus√£o
  - Relat√≥rio de classifica√ß√£o detalhado

**Visualiza√ß√µes**:
- Curva ROC com AUC
- Gr√°fico de vari√¢ncia explicada acumulada pelo PCA
- Interpreta√ß√£o autom√°tica dos resultados

**Informa√ß√µes T√©cnicas**:
- Dataset: Sonar (detec√ß√£o de minas vs rochas)
- Classifica√ß√£o bin√°ria: R (rock) = 0, M (mine) = 1
- Estrat√©gia: StratifiedKFold 5-fold cross-validation
- Scoring: ROC AUC para otimiza√ß√£o
- Pruning: Otimiza√ß√£o autom√°tica do ccp_alpha

---

### TP04 - Feature Engineering com K-Means e SVM

**Arquivo**: `experimento_kmeans_svm.ipynb`

**T√©cnicas Implementadas**:
- **Clustering**: K-Means para feature engineering
- **Classificadores**: SVM (Linear, Polynomial, RBF) e Random Forest
- **Feature Engineering**: Dist√¢ncia ao centr√≥ide mais pr√≥ximo
- **Otimiza√ß√£o**: GridSearchCV para m√∫ltiplos kernels

**Features Implementadas**:
- Sele√ß√£o autom√°tica de K √≥timo via:
  - M√©todo do cotovelo (in√©rcia)
  - √çndice de silhueta
- Cria√ß√£o de nova feature: dist√¢ncia m√≠nima aos centr√≥ides
- Compara√ß√£o baseline vs feature expandida
- GridSearch para SVM e Random Forest

**Resultados Obtidos**:
- **An√°lise Comparativa**:
  - Performance baseline vs com feature de clustering
  - Impacto de diferentes valores de K
  - M√∫ltiplas m√©tricas (Accuracy, Precision, Recall, F1, AUC)

**Visualiza√ß√µes**:
- Gr√°ficos de m√©todo do cotovelo e silhueta
- Curvas ROC comparativas (baseline vs expandido)
- An√°lise de performance por valor de K
- Comparativo de ganhos por modelo

**Informa√ß√µes T√©cnicas**:
- Dataset: Spotify tracks (114.000 amostras, 21 features)
- Pr√©-processamento: StandardScaler para SVM e K-Means
- Estrat√©gia: Hold-out (80%/20%) com estratifica√ß√£o
- Feature Engineering: Dist√¢ncia euclidiana aos centr√≥ides
- Modelos: SVM (3 kernels) + Random Forest com hiperpar√¢metros otimizados

---

### TP05 - Pipeline Completo de Text Mining

**Arquivo**: `text_ml_pipeline.ipynb`

**T√©cnicas Implementadas**:
- **Modelagem de T√≥picos**: Latent Dirichlet Allocation (LDA)
- **Classifica√ß√£o**: Regress√£o Log√≠stica com TF-IDF
- **Visualiza√ß√£o**: t-SNE para agrupamentos
- **Explicabilidade**: LIME e SHAP

**Features Implementadas**:
- **Pipeline Completo de Texto**:
  - Limpeza e pr√©-processamento autom√°tico
  - Sele√ß√£o autom√°tica de n√∫mero de t√≥picos (coer√™ncia/perplexidade)
  - TF-IDF com n-gramas e stop words
  - GridSearch para otimiza√ß√£o de hiperpar√¢metros

**Modelagem de T√≥picos**:
- LDA com sele√ß√£o autom√°tica de n√∫mero de t√≥picos
- An√°lise de coer√™ncia (c_v) ou perplexidade como proxy
- Extra√ß√£o e salvamento de top palavras por t√≥pico

**Visualiza√ß√µes e Explicabilidade**:
- **t-SNE**: Visualiza√ß√£o 2D dos documentos
- **LIME**: Explica√ß√£o local de inst√¢ncias individuais
- **SHAP**: An√°lise de import√¢ncia de features globais
- **Curva ROC**: Avalia√ß√£o de performance

**Resultados Obtidos**:
- **M√©tricas de Classifica√ß√£o**:
  - Acur√°cia: 90.45%
  - Precis√£o: 89.93%
  - Recall: 91.10%
  - F1-Score: 90.51%
  - AUC-ROC: 96.60%

**An√°lise Autom√°tica**:
- Identifica√ß√£o de palavras mais discriminativas
- An√°lise de t√≥picos extra√≠dos pelo LDA
- Gera√ß√£o autom√°tica de conclus√µes baseadas em m√©tricas

**Informa√ß√µes T√©cnicas**:
- Dataset: IMDB Movie Reviews (50.000 reviews)
- Classifica√ß√£o de sentimento bin√°ria (positivo/negativo)
- Pipeline: TF-IDF ‚Üí Regress√£o Log√≠stica
- Explicabilidade: LIME + SHAP com visualiza√ß√µes
- Outputs automatizados: gr√°ficos, relat√≥rios HTML e CSV

---

## üõ†Ô∏è Tecnologias e Bibliotecas Utilizadas

### Core ML/Data Science
- **scikit-learn**: Algoritmos de ML, pr√©-processamento, valida√ß√£o
- **pandas**: Manipula√ß√£o e an√°lise de dados
- **numpy**: Computa√ß√£o num√©rica
- **matplotlib/seaborn**: Visualiza√ß√£o de dados

### T√©cnicas Espec√≠ficas
- **TF-IDF**: Vetoriza√ß√£o de texto (TP02, TP05)
- **PCA**: Redu√ß√£o de dimensionalidade (TP03)
- **LDA**: Modelagem de t√≥picos (TP05)
- **t-SNE**: Visualiza√ß√£o de alta dimensionalidade (TP05)

### Explicabilidade e Interpreta√ß√£o
- **LIME**: Local Interpretable Model-agnostic Explanations (TP05)
- **SHAP**: SHapley Additive exPlanations (TP05)

### Algoritmos Implementados
- **KNN**: K-Nearest Neighbors (TP01, TP02)
- **Decision Tree**: √Årvores de decis√£o com pruning (TP03)
- **SVM**: Support Vector Machines (kernels linear, poly, RBF) (TP04)
- **Random Forest**: Ensemble de √°rvores (TP04)
- **Logistic Regression**: Regress√£o log√≠stica (TP05)
- **K-Means**: Clustering para feature engineering (TP04)

## üìà Principais Contribui√ß√µes Acad√™micas

1. **An√°lise Comparativa de Algoritmos**: Compara√ß√£o sistem√°tica de diferentes abordagens em diversos tipos de dados

2. **Feature Engineering Avan√ßado**: Uso de clustering para cria√ß√£o de novas features (TP04)

3. **Pipeline Completo de Text Mining**: Implementa√ß√£o end-to-end desde pr√©-processamento at√© explicabilidade (TP05)

4. **Otimiza√ß√£o de Hiperpar√¢metros**: GridSearchCV sistem√°tico em todos os projetos

5. **Valida√ß√£o Robusta**: Uso de valida√ß√£o cruzada estratificada e m√∫ltiplas m√©tricas

6. **Interpretabilidade**: Implementa√ß√£o de t√©cnicas de explicabilidade (LIME, SHAP)

7. **Visualiza√ß√£o Avan√ßada**: t-SNE, curvas ROC, matrizes de confus√£o e an√°lises gr√°ficas

## üéØ Datasets Utilizados

- **Heart Disease**: Classifica√ß√£o m√©dica bin√°ria
- **Fake News**: Detec√ß√£o de not√≠cias falsas (texto)
- **Sonar**: Detec√ß√£o de objetos subaqu√°ticos
- **Spotify Tracks**: Classifica√ß√£o de caracter√≠sticas musicais
- **IMDB Reviews**: An√°lise de sentimento em reviews de filmes

## üìä M√©tricas e Avalia√ß√£o

Todos os projetos implementam avalia√ß√£o abrangente com:
- Acur√°cia, Precis√£o, Recall, F1-Score
- AUC-ROC e curvas ROC
- Matrizes de confus√£o
- Valida√ß√£o cruzada estratificada
- An√°lise de hiperpar√¢metros
- Interpreta√ß√£o autom√°tica de resultados

---

**Autor**: Jorge Nascimento  
**Objetivo**: Demonstra√ß√£o pr√°tica de t√©cnicas de Machine Learning e Text Mining com foco em reprodutibilidade e interpretabilidade.