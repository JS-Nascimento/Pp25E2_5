{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T00:13:48.025479Z",
     "start_time": "2025-09-17T00:06:49.978251Z"
    }
   },
   "source": [
    "# ========================================\n",
    "# PARTE 1: CARREGAMENTO E PREPARAÇÃO DOS DADOS\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, classification_report, roc_curve, auc)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "plt.switch_backend(\"Agg\")  # garante salvar figuras sem precisar de display\n",
    "\n",
    "\n",
    "try:\n",
    "    from tqdm.std import TqdmWarning\n",
    "    warnings.filterwarnings('ignore', category=TqdmWarning)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "DATASET_PATH = \"IMDB Dataset.csv\"\n",
    "OUTPUT_DIR = Path(\"outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Amostragens para etapas custosas (ajuste conforme sua máquina)\n",
    "LDA_SAMPLE = 5000         # documentos usados para selecionar N de tópicos (None = usar todos)\n",
    "TSNE_SAMPLE = 2000        # documentos usados no t-SNE\n",
    "SHAP_SAMPLE = 200         # documentos para SHAP (apenas uma amostra, para não ficar pesado)\n",
    "LIME_INDEX = 0            # índice do exemplo de teste para LIME/Force-plot\n",
    "\n",
    "# Utilidades\n",
    "def _find_text_and_label_columns(df: pd.DataFrame) -> Tuple[str, str]:\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    text_candidates = [\"review\", \"texto\", \"text\", \"content\", \"comentario\"]\n",
    "    label_candidates = [\"sentiment\", \"label\", \"rotulo\", \"classe\", \"target\"]\n",
    "    text_col = next((cols[c] for c in text_candidates if c in cols), None)\n",
    "    label_col = next((cols[c] for c in label_candidates if c in cols), None)\n",
    "    if not text_col or not label_col:\n",
    "        raise ValueError(f\"Não encontrei colunas de texto/label. Colunas disponíveis: {list(df.columns)}\")\n",
    "    return text_col, label_col\n",
    "\n",
    "def _normalize_sentiment(series: pd.Series) -> pd.Series:\n",
    "    # mapeia 'positive'/'negative' -> 1/0, ou tenta converter automaticamente\n",
    "    s = series.astype(str).str.lower().str.strip()\n",
    "    mapping = {\"positive\": 1, \"negativo\": 0, \"negative\": 0, \"pos\": 1, \"neg\": 0, \"1\": 1, \"0\": 0}\n",
    "    out = s.map(lambda x: mapping.get(x, None))\n",
    "    # se ainda tiver None, tenta converter para int\n",
    "    if out.isna().any():\n",
    "        try:\n",
    "            out2 = s.astype(int)\n",
    "            out = out.fillna(out2)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if out.isna().any():\n",
    "        # ultimo recurso: binariza assumindo duas classes distintas\n",
    "        uniq = sorted(s.unique())\n",
    "        if len(uniq) == 2:\n",
    "            out = s.map({uniq[0]: 0, uniq[1]: 1})\n",
    "    if out.isna().any():\n",
    "        raise ValueError(\"Não foi possível normalizar a coluna de sentimento/label para 0/1.\")\n",
    "    return out.astype(int)\n",
    "\n",
    "def _basic_clean(txt: str) -> str:\n",
    "    txt = txt or \"\"\n",
    "    txt = re.sub(r\"<br\\s*/?>\", \" \", txt, flags=re.I)  # remove <br/>\n",
    "    txt = re.sub(r\"[^A-Za-z0-9\\s']\", \" \", txt)       # mantém letras, números e apóstrofo\n",
    "    txt = re.sub(r\"\\s+\", \" \", txt).strip().lower()\n",
    "    return txt\n",
    "\n",
    "# Carrega dataset\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(f\"Arquivo não encontrado: {DATASET_PATH}. Ajuste a variável DATASET_PATH no topo do notebook.\")\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH, encoding=\"utf-8\")\n",
    "text_col, label_col = _find_text_and_label_columns(df)\n",
    "\n",
    "df = df[[text_col, label_col]].dropna()\n",
    "df[text_col] = df[text_col].astype(str).map(_basic_clean)\n",
    "df[label_col] = _normalize_sentiment(df[label_col])\n",
    "\n",
    "# Embaralha para reduzir viés\n",
    "df = df.sample(frac=1.0, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "X = df[text_col].values\n",
    "y = df[label_col].values\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Total de documentos: {len(df)} | Treino: {len(X_train_text)} | Teste: {len(X_test_text)}\")\n",
    "\n",
    "# ========================================\n",
    "# PARTE 2: CRIAÇÃO DAS FEATURES (TF-IDF)\n",
    "# ========================================\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    stop_words='english'\n",
    ")\n",
    "X_train = tfidf.fit_transform(X_train_text)\n",
    "X_test  = tfidf.transform(X_test_text)\n",
    "\n",
    "print(f\"Dimensão TF-IDF: {X_train.shape}\")\n",
    "\n",
    "# ========================================\n",
    "# PARTE 3: MODELAGEM DE TÓPICOS COM LDA (com busca de N tópicos por coerência/perplexidade)\n",
    "# ========================================\n",
    "\n",
    "# Para LDA, é recomendado usar contagens (CountVectorizer)\n",
    "count_vect = CountVectorizer(\n",
    "    max_features=30000,\n",
    "    ngram_range=(1, 1),\n",
    "    min_df=5,\n",
    "    stop_words='english'\n",
    ")\n",
    "# Usa amostra para acelerar\n",
    "lda_texts = X_train_text[:LDA_SAMPLE] if (LDA_SAMPLE and LDA_SAMPLE < len(X_train_text)) else X_train_text\n",
    "counts = count_vect.fit_transform(lda_texts)\n",
    "\n",
    "# Tenta usar gensim para coerência (c_v). Se não disponível, usa perplexidade como proxy.\n",
    "HAS_GENSIM = False\n",
    "try:\n",
    "    import gensim\n",
    "    import gensim.corpora as corpora\n",
    "    from gensim.models.coherencemodel import CoherenceModel\n",
    "    HAS_GENSIM = True\n",
    "except Exception as e:\n",
    "    print(\"[AVISO] gensim indisponível. A seleção de tópicos usará perplexidade como proxy.\")\n",
    "\n",
    "def _tokenize_for_gensim(texts: List[str]) -> List[List[str]]:\n",
    "    return [re.findall(r\"[a-zA-Z']+\", t.lower()) for t in texts]\n",
    "\n",
    "def select_n_topics(counts_mat, count_vect, texts, topic_range=(5, 10, 15, 20)) -> Tuple[int, Dict[int, float]]:\n",
    "    from sklearn.decomposition import LatentDirichletAllocation\n",
    "    scores = {}\n",
    "    if HAS_GENSIM:\n",
    "        tokenized = _tokenize_for_gensim(texts)\n",
    "        dictionary = corpora.Dictionary(tokenized)\n",
    "        for nt in range(topic_range[0], topic_range[-1] + 1, 5):\n",
    "            lda = LatentDirichletAllocation(n_components=nt, random_state=RANDOM_STATE, learning_method=\"batch\", max_iter=10)\n",
    "            lda.fit(counts_mat)\n",
    "            # top palavras por tópico\n",
    "            vocab = np.array(count_vect.get_feature_names_out())\n",
    "            topics = []\n",
    "            for i in range(nt):\n",
    "                comp = lda.components_[i]\n",
    "                top_idx = np.argsort(comp)[::-1][:20]\n",
    "                topics.append(list(vocab[top_idx]))\n",
    "            cm = CoherenceModel(topics=topics, texts=tokenized, dictionary=dictionary, coherence='c_v')\n",
    "            coherence = float(cm.get_coherence())\n",
    "            scores[nt] = coherence\n",
    "            print(f\"[coherence c_v] tópicos={nt}: {coherence:.4f}\")\n",
    "        best_n = max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "    else:\n",
    "        for nt in range(topic_range[0], topic_range[-1] + 1, 5):\n",
    "            lda = LatentDirichletAllocation(n_components=nt, random_state=RANDOM_STATE, learning_method=\"batch\", max_iter=10)\n",
    "            lda.fit(counts_mat)\n",
    "            perp = float(lda.perplexity(counts_mat))\n",
    "            # Menor perplexidade é melhor; para padronizar, salvamos -perp como \"score\"\n",
    "            scores[nt] = -perp\n",
    "            print(f\"[perplexity proxy] tópicos={nt}: perplexity={perp:.2f}\")\n",
    "        best_n = max(scores.items(), key=lambda kv: kv[1])[0]\n",
    "    return best_n, scores\n",
    "\n",
    "best_n_topics, topic_scores = select_n_topics(counts, count_vect, list(lda_texts))\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_final = LatentDirichletAllocation(n_components=best_n_topics, random_state=RANDOM_STATE, learning_method=\"batch\", max_iter=15)\n",
    "# Ajusta em amostra para velocidade\n",
    "lda_final.fit(counts)\n",
    "\n",
    "# Extrai top palavras por tópico\n",
    "vocab_cv = np.array(count_vect.get_feature_names_out())\n",
    "TOPK_WORDS = 15\n",
    "topics_words = []\n",
    "for k in range(best_n_topics):\n",
    "    comp = lda_final.components_[k]\n",
    "    top_idx = np.argsort(comp)[::-1][:TOPK_WORDS]\n",
    "    topics_words.append((k, list(vocab_cv[top_idx])))\n",
    "\n",
    "# Salva tópicos em CSV para referência\n",
    "pd.DataFrame([{\"topic\": k, \"top_words\": \", \".join(words)} for k, words in topics_words]).to_csv(OUTPUT_DIR / \"lda_topics.csv\", index=False)\n",
    "\n",
    "print(f\"Melhor número de tópicos: {best_n_topics}\")\n",
    "print(\"Exemplo de tópicos (top palavras):\")\n",
    "for k, words in topics_words[: min(5, len(topics_words))]:\n",
    "    print(f\"  Tópico {k}: {', '.join(words)}\")\n",
    "\n",
    "# ========================================\n",
    "# PARTE 4: CLASSIFICAÇÃO DE TEXTOS (com busca de hiperparâmetros)\n",
    "# ========================================\n",
    "\n",
    "# Usaremos TF-IDF + Regressão Logística\n",
    "base_clf = LogisticRegression(max_iter=2000, solver='liblinear', class_weight=None, random_state=RANDOM_STATE)\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    \"logisticregression__penalty\": [\"l2\"]\n",
    "}\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        max_features=50000, ngram_range=(1,2), min_df=5, stop_words='english'\n",
    "    ),\n",
    "    base_clf\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X_train_text, y_train)\n",
    "\n",
    "best_pipeline = grid.best_estimator_\n",
    "print(f\"Melhor pipeline: {best_pipeline}\")\n",
    "print(f\"Melhor F1 (validação): {grid.best_score_:.4f}\")\n",
    "\n",
    "# ========================================\n",
    "# PARTE 5: AVALIAÇÃO DE DESEMPENHO (Precisão, Recall, F1, AUC-ROC)\n",
    "# ========================================\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test_text)\n",
    "# Para AUC, precisamos de probabilidade da classe positiva\n",
    "try:\n",
    "    y_proba = best_pipeline.predict_proba(X_test_text)[:, 1]\n",
    "except Exception:\n",
    "    # fallback se o classificador não suportar predict_proba\n",
    "    # usa decisão como score (não calibrado)\n",
    "    y_proba = best_pipeline.decision_function(X_test_text)\n",
    "    # normaliza para [0,1]\n",
    "    y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min() + 1e-9)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "auc_roc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(\"\\n=== MÉTRICAS DE TESTE ===\")\n",
    "print(f\"Acurácia:  {acc:.4f}\")\n",
    "print(f\"Precisão:  {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "print(f\"AUC-ROC:   {auc_roc:.4f}\")\n",
    "print(\"\\nRelatório de Classificação:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=1)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('Curva ROC - Classificador (Teste)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"roc_curve.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ========================================\n",
    "# PARTE 6: t-SNE PARA VISUALIZAÇÃO DOS AGRUPAMENTOS\n",
    "# ========================================\n",
    "\n",
    "# Para t-SNE em texto, é comum reduzir com SVD antes (para ~50 dims) e depois aplicar t-SNE\n",
    "svd = TruncatedSVD(n_components=50, random_state=RANDOM_STATE)\n",
    "X_all = tfidf.fit_transform(df[text_col].values)  # usa TF-IDF (fora do pipeline p/ visualizar todo o dataset)\n",
    "X_all_svd = svd.fit_transform(X_all)\n",
    "\n",
    "# Amostra para t-SNE (p/ performance)\n",
    "tsne_idx = np.arange(len(df))\n",
    "if TSNE_SAMPLE and TSNE_SAMPLE < len(df):\n",
    "    rng = np.random.default_rng(RANDOM_STATE)\n",
    "    tsne_idx = rng.choice(len(df), size=TSNE_SAMPLE, replace=False)\n",
    "\n",
    "X_tsne_input = X_all_svd[tsne_idx]\n",
    "y_tsne = df[label_col].values[tsne_idx]\n",
    "\n",
    "# Compatibilidade de versões: algumas versões usam `n_iter`, outras `max_iter` (prefira max_iter p/ evitar FutureWarning)\n",
    "from inspect import signature\n",
    "tsne_kwargs = dict(n_components=2, perplexity=30, random_state=RANDOM_STATE, init='pca', learning_rate='auto')\n",
    "sig = signature(TSNE.__init__)\n",
    "if 'max_iter' in sig.parameters:\n",
    "    tsne_kwargs['max_iter'] = 1000\n",
    "elif 'n_iter' in sig.parameters:\n",
    "    tsne_kwargs['n_iter'] = 1000\n",
    "\n",
    "tsne = TSNE(**tsne_kwargs)\n",
    "X_2d = tsne.fit_transform(X_tsne_input)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "scatter = plt.scatter(X_2d[:,0], X_2d[:,1], c=y_tsne, s=8, alpha=0.7)\n",
    "plt.title(\"t-SNE dos Documentos (cores = rótulos de sentimento)\")\n",
    "plt.xlabel(\"t-SNE 1\")\n",
    "plt.ylabel(\"t-SNE 2\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"tsne_plot.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(f\"t-SNE salvo em: {OUTPUT_DIR / 'tsne_plot.png'}\")\n",
    "\n",
    "# ========================================\n",
    "# PARTE 7: EXPLICABILIDADE (LIME, SHAP, FORCE-PLOT) + ANÁLISE DOS RESULTADOS\n",
    "# ========================================\n",
    "\n",
    "# Checagem/instalação automática de dependências opcionais (LIME/SHAP)\n",
    "try:\n",
    "    import importlib, sys, subprocess\n",
    "    def _ensure_module(mod_name: str, pip_name: str = None, version: str = None) -> bool:\n",
    "        try:\n",
    "            importlib.import_module(mod_name)\n",
    "            return True\n",
    "        except Exception:\n",
    "            try:\n",
    "                pkg = pip_name or mod_name\n",
    "                spec = f\"{pkg}=={version}\" if version else pkg\n",
    "                print(f\"[INFO] Instalando pacote '{spec}' (auto)...\")\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", spec])\n",
    "                importlib.import_module(mod_name)\n",
    "                return True\n",
    "            except Exception as _e:\n",
    "                print(f\"[AVISO] Não foi possível instalar/importar '{mod_name}': {_e}\")\n",
    "                return False\n",
    "    _ensure_module(\"lime\", \"lime\", \"0.2.0.1\")\n",
    "    _ensure_module(\"shap\", \"shap\", \"0.46.0\")\n",
    "except Exception:\n",
    "    # se a checagem falhar por algum motivo, segue o fluxo normal; os blocos abaixo ainda tratarão exceções\n",
    "    pass\n",
    "\n",
    "# ---- LIME ----\n",
    "LIME_OK = True\n",
    "try:\n",
    "    from lime.lime_text import LimeTextExplainer\n",
    "    class_names = [\"negativo\", \"positivo\"]\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    def predict_proba_text(texts: List[str]):\n",
    "        # usa o best_pipeline encontrado (TF-IDF + LR)\n",
    "        try:\n",
    "            return best_pipeline.predict_proba(texts)\n",
    "        except Exception:\n",
    "            # se não houver predict_proba, tenta decision_function com normalização\n",
    "            scores = best_pipeline.decision_function(texts)\n",
    "            scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)\n",
    "            # retorna proba para duas classes\n",
    "            probs = np.vstack([1 - scores, scores]).T\n",
    "            return probs\n",
    "    sample_text = X_test_text[LIME_INDEX if 0 <= LIME_INDEX < len(X_test_text) else 0]\n",
    "    exp = explainer.explain_instance(sample_text, predict_proba_text, num_features=10, labels=[0,1])\n",
    "    lime_path = OUTPUT_DIR / \"lime_sample.html\"\n",
    "    exp.save_to_file(str(lime_path))\n",
    "    print(f\"LIME salvo em: {lime_path}\")\n",
    "except Exception as e:\n",
    "    LIME_OK = False\n",
    "    print(f\"[AVISO] LIME não pôde ser executado: {e}\")\n",
    "\n",
    "# ---- SHAP ----\n",
    "SHAP_OK = True\n",
    "try:\n",
    "    import shap\n",
    "\n",
    "    # Extrai componentes do pipeline\n",
    "    tfidf_vec = None\n",
    "    logreg = None\n",
    "    for step_name, step_est in best_pipeline.named_steps.items():\n",
    "        if isinstance(step_est, TfidfVectorizer):\n",
    "            tfidf_vec = step_est\n",
    "        if isinstance(step_est, LogisticRegression):\n",
    "            logreg = step_est\n",
    "    if tfidf_vec is None or logreg is None:\n",
    "        raise RuntimeError(\"Não encontrei TfidfVectorizer ou LogisticRegression no pipeline final.\")\n",
    "\n",
    "    X_train_tfidf = tfidf_vec.transform(X_train_text)\n",
    "    # amostra para SHAP\n",
    "    shap_idx = np.arange(X_train_tfidf.shape[0])\n",
    "    if SHAP_SAMPLE and SHAP_SAMPLE < len(shap_idx):\n",
    "        rng = np.random.default_rng(RANDOM_STATE)\n",
    "        shap_idx = rng.choice(len(shap_idx), size=SHAP_SAMPLE, replace=False)\n",
    "    X_bg = X_train_tfidf[shap_idx]\n",
    "\n",
    "    # 1º tentamos API antiga com 'interventional' (compatível com muitas instalações)\n",
    "    explainer = None\n",
    "    shap_values = None\n",
    "    try:\n",
    "        explainer = shap.LinearExplainer(logreg, X_bg, feature_perturbation=\"interventional\")\n",
    "        X_test_tfidf = tfidf_vec.transform(X_test_text[:SHAP_SAMPLE if SHAP_SAMPLE else 200])\n",
    "        shap_values = explainer.shap_values(X_test_tfidf)\n",
    "        expected_value = explainer.expected_value\n",
    "        api_mode = \"legacy\"\n",
    "    except Exception as e_old:\n",
    "        # 2º fallback: nova API com masker\n",
    "        try:\n",
    "            masker = shap.maskers.Independent(X_bg)\n",
    "            explainer = shap.Explainer(logreg, masker)\n",
    "            X_test_tfidf = tfidf_vec.transform(X_test_text[:SHAP_SAMPLE if SHAP_SAMPLE else 200])\n",
    "            explanation = explainer(X_test_tfidf)\n",
    "            shap_values = explanation  # Explanation object\n",
    "            expected_value = explanation.base_values.mean() if hasattr(explanation, \"base_values\") else explainer.expected_value\n",
    "            api_mode = \"masker\"\n",
    "        except Exception as e_new:\n",
    "            raise RuntimeError(f\"Falha no SHAP (antigo e novo): {e_old} | {e_new}\")\n",
    "\n",
    "    feature_names = tfidf_vec.get_feature_names_out()\n",
    "\n",
    "    # summary plot\n",
    "    plt.figure()\n",
    "    if api_mode == \"legacy\":\n",
    "        shap.summary_plot(shap_values, X_test_tfidf, feature_names=feature_names, show=False)\n",
    "    else:\n",
    "        shap.summary_plot(shap_values, feature_names=feature_names, show=False)\n",
    "    shap_summary_path = OUTPUT_DIR / \"shap_summary.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(shap_summary_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"SHAP summary salvo em: {shap_summary_path}\")\n",
    "\n",
    "    # force plot para um exemplo\n",
    "    shap_force_path = OUTPUT_DIR / \"shap_force.html\"\n",
    "    if api_mode == \"legacy\":\n",
    "        i_force = 0\n",
    "        plot_obj = shap.force_plot(expected_value, shap_values[i_force,:], matplotlib=False)\n",
    "        shap.save_html(str(shap_force_path), plot_obj)\n",
    "    else:\n",
    "        # usa o primeiro exemplo do Explanation\n",
    "        plot_obj = shap.plots.force(shap_values[0], matplotlib=False)\n",
    "        shap.save_html(str(shap_force_path), plot_obj)\n",
    "    print(f\"SHAP force-plot salvo em: {shap_force_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    SHAP_OK = False\n",
    "    print(f\"[AVISO] SHAP não pôde ser executado: {e}\")\n",
    "\n",
    "# ---- ANÁLISE AUTOMÁTICA (conclusões) ----\n",
    "# 1) Resumo de métricas\n",
    "conclusoes = []\n",
    "conclusoes.append(f\"(1) Classificador final: {type(best_pipeline.named_steps['logisticregression']).__name__} com TF-IDF; F1_teste={f1:.4f}, AUC={auc_roc:.4f}\")\n",
    "\n",
    "# 2) Principais features (coeficientes) do modelo\n",
    "try:\n",
    "    logreg = best_pipeline.named_steps[\"logisticregression\"]\n",
    "    vec = best_pipeline.named_steps[\"tfidfvectorizer\"]\n",
    "    coefs = logreg.coef_[0]\n",
    "    idx_top_pos = np.argsort(coefs)[-15:][::-1]\n",
    "    idx_top_neg = np.argsort(coefs)[:15]\n",
    "    top_pos_words = [vec.get_feature_names_out()[i] for i in idx_top_pos]\n",
    "    top_neg_words = [vec.get_feature_names_out()[i] for i in idx_top_neg]\n",
    "    conclusoes.append(\"(2) Palavras mais pró-positivo (amostras): \" + \", \".join(top_pos_words[:10]))\n",
    "    conclusoes.append(\"(3) Palavras mais pró-negativo (amostras): \" + \", \".join(top_neg_words[:10]))\n",
    "except Exception:\n",
    "    conclusoes.append(\"(2-3) Não foi possível extrair coeficientes/top palavras.\")\n",
    "\n",
    "# 3) LDA: número de tópicos e exemplo de tópicos\n",
    "conclusoes.append(f\"(4) LDA selecionou {best_n_topics} tópicos (por {'coerência c_v' if HAS_GENSIM else 'perplexidade-proxy'}).\")\n",
    "if topics_words:\n",
    "    ex = \";  \".join([f\"T{k}: \" + \", \".join(words[:5]) for k, words in topics_words[:min(3, len(topics_words))]])\n",
    "    conclusoes.append(f\"(5) Tópicos (exemplo): {ex}\")\n",
    "\n",
    "# 4) t-SNE: apenas indicativo visual\n",
    "conclusoes.append(\"(6) t-SNE salvo em outputs/tsne_plot.png para inspeção visual de separação/aglomerados.\")\n",
    "\n",
    "# 5) LIME/SHAP status\n",
    "conclusoes.append(f\"(7) LIME {'ok' if LIME_OK else 'falhou'}; SHAP {'ok' if SHAP_OK else 'falhou'}. Consulte a pasta outputs/.\")\n",
    "\n",
    "print(\"\\n=== CONCLUSÕES (Geradas automaticamente) ===\")\n",
    "for c in conclusoes:\n",
    "    print(\"-\", c)\n",
    "print(\"\\nArquivos gerados na pasta 'outputs/': tsne_plot.png, roc_curve.png, lda_topics.csv, shap_summary.png, shap_force.html, lime_sample.html (quando disponíveis).\")\n"
   ],
   "id": "cc3163e5ac2deae2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de documentos: 50000 | Treino: 40000 | Teste: 10000\n",
      "Dimensão TF-IDF: (40000, 50000)\n",
      "[AVISO] gensim indisponível. A seleção de tópicos usará perplexidade como proxy.\n",
      "[perplexity proxy] tópicos=5: perplexity=3420.09\n",
      "[perplexity proxy] tópicos=10: perplexity=3662.32\n",
      "[perplexity proxy] tópicos=15: perplexity=3901.24\n",
      "[perplexity proxy] tópicos=20: perplexity=4120.65\n",
      "Melhor número de tópicos: 5\n",
      "Exemplo de tópicos (top palavras):\n",
      "  Tópico 0: film, story, love, life, great, man, time, young, war, best, world, good, movie, wife, does\n",
      "  Tópico 1: film, good, great, story, love, series, like, time, just, really, best, characters, episode, version, better\n",
      "  Tópico 2: movie, just, film, like, bad, really, good, don, time, movies, acting, make, seen, plot, watch\n",
      "  Tópico 3: film, story, films, characters, like, movie, character, just, director, way, time, horror, man, scenes, good\n",
      "  Tópico 4: movie, like, people, just, time, think, film, funny, good, movies, watch, really, great, love, life\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Melhor pipeline: Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(max_features=50000, min_df=5,\n",
      "                                 ngram_range=(1, 2), stop_words='english')),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=5.0, max_iter=2000, random_state=42,\n",
      "                                    solver='liblinear'))])\n",
      "Melhor F1 (validação): 0.9013\n",
      "\n",
      "=== MÉTRICAS DE TESTE ===\n",
      "Acurácia:  0.9045\n",
      "Precisão:  0.8993\n",
      "Recall:    0.9110\n",
      "F1-score:  0.9051\n",
      "AUC-ROC:   0.9660\n",
      "\n",
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9098    0.8980    0.9039      5000\n",
      "           1     0.8993    0.9110    0.9051      5000\n",
      "\n",
      "    accuracy                         0.9045     10000\n",
      "   macro avg     0.9046    0.9045    0.9045     10000\n",
      "weighted avg     0.9046    0.9045    0.9045     10000\n",
      "\n",
      "t-SNE salvo em: outputs\\tsne_plot.png\n",
      "[INFO] Instalando pacote 'lime==0.2.0.1' (auto)...\n",
      "[INFO] Instalando pacote 'shap==0.46.0' (auto)...\n",
      "LIME salvo em: outputs\\lime_sample.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Master\\miniconda3\\Lib\\site-packages\\shap\\explainers\\_linear.py:95: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP summary salvo em: outputs\\shap_summary.png\n",
      "SHAP force-plot salvo em: outputs\\shap_force.html\n",
      "\n",
      "=== CONCLUSÕES (Geradas automaticamente) ===\n",
      "- (1) Classificador final: LogisticRegression com TF-IDF; F1_teste=0.9051, AUC=0.9660\n",
      "- (2) Palavras mais pró-positivo (amostras): excellent, great, best, perfect, amazing, wonderful, brilliant, hilarious, favorite, superb\n",
      "- (3) Palavras mais pró-negativo (amostras): worst, awful, waste, bad, boring, terrible, disappointment, worse, dull, poor\n",
      "- (4) LDA selecionou 5 tópicos (por perplexidade-proxy).\n",
      "- (5) Tópicos (exemplo): T0: film, story, love, life, great;  T1: film, good, great, story, love;  T2: movie, just, film, like, bad\n",
      "- (6) t-SNE salvo em outputs/tsne_plot.png para inspeção visual de separação/aglomerados.\n",
      "- (7) LIME ok; SHAP ok. Consulte a pasta outputs/.\n",
      "\n",
      "Arquivos gerados na pasta 'outputs/': tsne_plot.png, roc_curve.png, lda_topics.csv, shap_summary.png, shap_force.html, lime_sample.html (quando disponíveis).\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
